---
title: 论文阅读-240807
tags: 
  - Notes
  - Summary
categories: 
  - [Paper]
date: 2024-08-07 00:00:00
---

**Advances in 3D Generation: A Survey**

<!-- more -->

这篇论文概括了3D生成的方法和技术，涵盖了3D表示、生成方法、数据集和应用等方面。

1. #### 神经场景表示

   3D场景表示有三种主要类型：显式表示、隐式表示和混合表示。

   ###### 显示表示

   显示表示通过描述3D场景的基本几何元素（如点、线、面）来表示场景。

   - 点云

     点云通过离散点在三维空间中的位置、颜色等信息表示场景。

   - 网格

     网格通过连接多个顶点形成复杂的几何结构。

   - 多层表示

     多层表示通过多个半透明彩色层表示场景，常用于实时新视图合成。

   ###### 隐式表示

   隐式表示通过数学函数来定义3D空间的属性，能够高效地建模复杂几何拓扑，但是优化过程较慢。

   - NeRFs（神经辐射场）

     NeRF通过查询隐式神经网络获取提及参数，生成连续的体素场。

   - Neural Implicit Surfaces（神经隐式曲面）

     神经隐式曲面通过神经网络处理3D坐标并生成一个标量值，表示点到曲面的有符号距离。这种方法使用于填充缺失信息、生成平滑连续的曲面。

   ###### 混合表示

   隐式表示能够高效地建模复杂几何拓扑，但是在优化过程中速度较慢；显示表示能快速收敛优化，但是需要大量的存储资源。混合表示是在两者之间的平衡。

   - Voxel Grids（体素网格）

     是一种在规则网格上存储粗略占用（内部/外部）值的方法。

   - Tri-plane（三平面）

     三平面将3D体积分解为三个正交平面，并在这些平面上表示3D形状的特征。

   - Hybrid Surface Representation（混合表面表示）

     DMTet是一种结合了显式和隐式形式的混合三维表面表示，它将3D空间分割成密集的四面体，形成一个显式的分区。通过整合显式和隐式表示，DMTet可以更高效地进行优化，并且可以无缝地转换为如网格表示等显式结构。在生成过程中，DMTet可以可微分地转换为网格，从而实现快速的高分辨率多视图渲染。

   <img src="https://pic-poivre.oss-cn-hangzhou.aliyuncs.com/pics/3b4bfc2927f8c6453e4f7be1626bad14-image.png" alt="3b4bfc2927f8c6453e4f7be1626bad14-image" style="zoom:80%;" />

2. #### **3D 生成方法**

   生成方法主要分为四类：前馈生成、优化生成、程序生成和生成新视图合成。

   ![image-20240812200600428](https://pic-poivre.oss-cn-hangzhou.aliyuncs.com/pics/image-20240812200600428.png)

   ###### 前馈生成

   前馈生成方法直接使用生成模型3D表示，不需要迭代优化，包括生成对抗网络（GANs）、扩散模型、自回归模型、变分自编码器（VAEs）和正规化流。

   GANs通过生成器和判别器的对抗训练生成逼真的3D数据；扩散模型通过模拟扩散过程生成高质量的数据样本；自回归模型通过条件概率生成序列数据；VAEs通过编码器和解码器生成新的数据样本；正规化流通过一系列可逆变换将简单分布映射到目标分布。

   <img src="https://pic-poivre.oss-cn-hangzhou.aliyuncs.com/pics/c083a3482084005addaef8c9696e9b18-image.png" alt="c083a3482084005addaef8c9696e9b18-image" style="zoom:80%;" />

   ###### 优化生成

   优化生成方法通过运行时优化生成3D模型，通常利用预训练的多模态网络根据用户指定的提示进行优化。

   这类方法包括文本到3D的生成和图像到3D的生成。文本到3D的生成方法如DreamFusion结合CLIP模型和SDS损失实现高保真度的3D内容生成；图像到3D的生成方法如RealFusion利用CLIP引导的物理渲染图像优化体积表示。

   ###### 程序生成

   程序生成方法通过一组规则创建3D模型和纹理，具有高效生成复杂且多样内容的能力。

   这类方法包括分形几何、L系统、噪声函数和元胞自动机。分形几何通过随机算法生成自然地形；L系统通过符号逻辑生成复杂的几何结构；噪声函数通过生成随机图案创建逼真的纹理和形状；元胞自动机通过细胞状态的变化生成各种3D对象和模式。

   ###### 生成新视图合成

   生成新视图合成方法利用生成技术解决新视图预测问题，特别是从单张输入图像生成多视图一致图像。这类方法主要使用2D扩散模型，生成高质量的图像并确保视图一致性。代表性的方法如Zero-1-to-3通过大规模扩散模型学习相机视点，实现零样本新视图合成。

   <img src="https://pic-poivre.oss-cn-hangzhou.aliyuncs.com/pics/3be3d3e293de359cfe1c6d129103d8f1-image.png" alt="3be3d3e293de359cfe1c6d129103d8f1-image" style="zoom: 33%;" />

   

3. #### **数据集**

   讨论了可用于训练 3D 生成方法的数据集、各种应用场景以及开放的挑战。

   <img src="https://pic-poivre.oss-cn-hangzhou.aliyuncs.com/pics/image-20240812205851671.png" alt="image-20240812205851671" style="zoom:80%;" />

   ###### 3D数据

   3D数据只要通过RGB-D传感器等技术扫描和重建得到。这类数据不仅用于3D生成，还用于改善2D视觉任务的性能、环境模拟和3D对象理解等。

   提到了几个早期的3D模型数据库，如Princeton Shape Benchmark和KXD12，并强调了大规模3D数据集对3D内容生成的重要性，如ObJavaerse和OmniObject3D。

   ###### 多视图图像数据

   ScanNet和Objectron是两个包含大量标注视频帧的数据集，而CO3D则扩展了HRL数据集，增加了视频数量。MVImgNet收集了来自日常生活真实世界对象的6.5百万帧多视图图像。

   ###### 单视图图像数据

   由于单视图图像的不确定性，直接用于3D生成存在挑战，因此提出了多个单视图图像数据集，如FFHQ和AFHQ，用于2D图像合成和3D生成。此外，还提到了一些基于形状Net的合成单视图数据集，以及专门用于人体和动物面部生成的方法，如CelebA和Cats数据集。

4. #### 3D生成技术的应用

   ###### 3D数字人

   3D数字人主要分为两类：一类是无纹理形状生成，另一类是有纹理身体生成。

   无纹理形状生成方法通过预测SMPL参数来生成人体模型，而有纹理身体生成方法则通过条件生成具有真实细节的3D衣物。近年来，基于文本驱动的方法在这一领域取得了显著进展，如AvatarCLIP和AvatarCraft。

   ###### 3D面部生成

   3D面部生成任务旨在生成高质量的人脸图像，这些图像可以从不同视点观看。

   主要类别包括个性化头部头像创建、神经隐式3D可变形模型（3DMMs）和生成3D面部模型。

   个性化头部头像创建方法通常需要高质量的多视图图像，而神经隐式3DMMs和生成3D面部模型则能够生成多视图一致的高分辨率图像。

   ###### 一般场景生成

   一般场景生成方法基于语义或类别相似性设计3D模型生成框架。

   这些方法分为两类：以对象为中心的资源生成和面向外部的场景生成。以对象为中心的资源生成进一步细分为无纹理形状生成和有纹理资源生成。面向外部的场景生成则利用扩散模型的图像修复能力来实现场景生成任务。

   ###### 3D编辑

   3D编辑任务分为全局编辑和局部编辑。

   全局编辑旨在改变整个3D场景的风格特征或对单个形象的操作。

   局部编辑专注于修改特定区域，包括外观操作、几何变形、对象/语义级复制/删除以及移动/移除等。最近的研究还包括基于文本描述的3D场景生成，如InstructNeRF2NeRF和DreamEditor。

